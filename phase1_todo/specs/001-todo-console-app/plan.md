# Implementation Plan: In-Memory Python Todo Console Application

**Branch**: `001-todo-console-app` | **Date**: 2026-01-01 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `specs/001-todo-console-app/spec.md`

## Summary

Build a lightweight, session-based CLI task manager with in-memory storage. Users interact via a numbered console menu to perform CRUD operations (Create, Read, Update, Delete, Mark Complete) on tasks. Each task has an auto-incrementing integer ID, title, description, and completion status. Data persists only during the application session and is lost on exit.

**Technical Approach**: Python 3.13+ with `dataclasses` for the Task model, a `TodoManager` class encapsulating business logic, and a simple `main.py` menu loop using `match/case` for command routing. UV package manager for dependency management. Flat `src/` structure for Phase I simplicity.

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: Standard library only (no external packages for Phase I)
**Storage**: In-memory Python list (no persistence layer)
**Testing**: Manual validation via 5 functional tests (Add, View, Update, Delete, Mark Complete)
**Target Platform**: Cross-platform (Windows, macOS, Linux) with Python 3.13+ installed
**Project Type**: Single CLI application
**Performance Goals**:
  - Operations complete in <1 second for up to 1,000 tasks
  - Task creation and display under 5 seconds (per SC-001)
  - Linear search acceptable for ID lookups (O(n) complexity)
**Constraints**:
  - ZERO file I/O or database operations (in-memory only)
  - No external package dependencies beyond standard library
  - Full type hints on all functions/methods (PEP 484)
  - PEP 8 compliance mandatory
  - UV project structure required
**Scale/Scope**: Single-user, single-session usage; optimized for 10-1,000 tasks per session

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

✅ **Strict Spec-Driven Development**: Plan derives directly from spec.md; no manual coding
✅ **Modularity**: Clear separation - Task model, TodoManager logic, CLI interface
✅ **Clean Code Standards**: Type hints, PEP 8, docstrings enforced
✅ **Environment**: UV package manager, Python 3.13+, `/src` directory structure
✅ **ID-Based Management**: Auto-incrementing integer IDs for all CRUD operations
✅ **Zero External Dependencies**: In-memory only, no files/databases/network
✅ **Tool Restriction**: No git/gh commands (user handles version control manually)
✅ **No Git/GitHub Operations**: Plan documents architecture only; implementation via `/sp.tasks`

**Constitution Alignment**: All 6 core principles satisfied. No complexity violations.

## Project Structure

### Documentation (this feature)

```text
specs/001-todo-console-app/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (architectural plan)
├── tasks.md             # Implementation tasks (generated by /sp.tasks)
└── checklists/
    ├── requirements.md  # Spec quality validation (completed)
    └── plan.md          # Plan quality validation (generated)
```

### Source Code (repository root)

```text
phase1_todo/
├── src/
│   ├── __init__.py          # Package marker
│   ├── todo.py              # Task dataclass + TodoManager logic
│   └── main.py              # CLI menu loop and entry point
│
├── tests/
│   └── manual_tests.md      # Manual test scenarios for 5 core features
│
├── pyproject.toml           # UV project configuration
├── README.md                # User-facing documentation
├── CLAUDE.md                # AI agent instructions (existing)
├── constitution.md          # Project principles (existing)
│
└── specs/                   # Feature specifications (existing)
```

**Structure Decision**: Flat `src/` directory (Option 1: Single project) chosen for Phase I simplicity. Only two source files needed: `todo.py` (model + logic) and `main.py` (interface). Minimal structure reduces cognitive overhead and aligns with "simplest viable change" principle from constitution. Future phases can refactor to package structure if complexity warrants.

**Rationale**:
- Only ~300-500 lines of code expected for Phase I
- Clear 3-layer separation even with 2 files (Model in `todo.py`, Controller/View in `main.py`)
- No submodules or complex imports needed
- Easy to understand and test

## Complexity Tracking

No constitution violations to justify. All decisions align with "simplest viable change" and Phase I scope constraints.

## Architecture Sketch

### Layer Separation

```
┌─────────────────────────────────────────────┐
│           CLI Interface Layer               │
│  (main.py - User I/O, Menu, Input Parsing) │
└─────────────────┬───────────────────────────┘
                  │ Function Calls
                  ▼
┌─────────────────────────────────────────────┐
│          Business Logic Layer               │
│ (TodoManager - CRUD operations, validation) │
└─────────────────┬───────────────────────────┘
                  │ Object Access
                  ▼
┌─────────────────────────────────────────────┐
│            Data Model Layer                 │
│   (Task dataclass - Structure, State)       │
└─────────────────┬───────────────────────────┘
                  │ In-Memory Storage
                  ▼
┌─────────────────────────────────────────────┐
│        Python Runtime Memory                │
│   (list[Task] - Session-scoped storage)     │
└─────────────────────────────────────────────┘
```

### Component Breakdown

#### 1. Data Model Layer (`src/todo.py`)

**Task Dataclass**:
```python
@dataclass
class Task:
    id: int
    title: str
    description: str
    is_completed: bool = False
```

**Design Decisions**:
- Use `@dataclass` for automatic `__init__`, `__repr__`, `__eq__` generation
- `is_completed: bool` over enum for simplicity (only 2 states)
- No timestamp fields (not required by spec; can add in future phase)
- Immutable after creation except for `is_completed`, `title`, `description` updates

**Justification**:
- Dataclasses reduce boilerplate while maintaining type safety
- Boolean status aligns with toggle behavior (FR-007)
- Minimal fields satisfy all functional requirements (FR-002, FR-003, FR-005)

#### 2. Business Logic Layer (`src/todo.py`)

**TodoManager Class**:
```python
class TodoManager:
    def __init__(self) -> None:
        self._tasks: list[Task] = []
        self._next_id: int = 1

    def add_task(title: str, description: str) -> Task: ...
    def get_all_tasks() -> list[Task]: ...
    def get_task_by_id(task_id: int) -> Task | None: ...
    def update_task(task_id: int, title: str | None, description: str | None) -> bool: ...
    def delete_task(task_id: int) -> bool: ...
    def toggle_completion(task_id: int) -> bool: ...
```

**Design Decisions**:
- Single `TodoManager` instance owns all tasks (singleton pattern via module-level instance)
- Private `_tasks` list prevents external mutation
- `_next_id` counter increments monotonically (never reused after deletion)
- Return `Task | None` or `bool` for operations (explicit success/failure signaling)
- Linear search for ID lookups (acceptable for <1,000 tasks per SC-004)

**Justification**:
- Encapsulation: All business rules in one class
- Predictable IDs: Sequential integers starting at 1 (FR-003)
- Type safety: Full type hints enable static analysis
- Simple error handling: None/False return values checked by caller

#### 3. CLI Interface Layer (`src/main.py`)

**Menu Loop Structure**:
```python
def main() -> None:
    manager = TodoManager()

    while True:
        display_menu()
        choice = get_user_input()

        match choice:
            case "1": handle_add_task(manager)
            case "2": handle_view_tasks(manager)
            case "3": handle_update_task(manager)
            case "4": handle_delete_task(manager)
            case "5": handle_toggle_completion(manager)
            case "6": break
            case _: print("Invalid choice")
```

**Design Decisions**:
- Python 3.13 `match/case` for command routing (cleaner than if/elif chains)
- Separate handler functions for each operation (single responsibility)
- `input()` for user prompts, `print()` for output (standard library only)
- Infinite loop with explicit `break` on exit (classic CLI pattern)
- Input validation in handlers (reject empty strings, invalid IDs)

**Justification**:
- `match/case` improves readability over if/elif ladder (FR-001)
- Modular handlers enable easier testing and modification
- Standard library functions sufficient for console I/O (no TUI library needed)
- Loop structure aligns with "menu returns after each operation" pattern

### Data Flow Example (Add Task)

```
User Input: "1" (Add Task)
    ↓
main.py: handle_add_task(manager)
    ↓
main.py: title = input("Enter title: ")
main.py: description = input("Enter description: ")
    ↓
main.py: task = manager.add_task(title, description)
    ↓
todo.py: TodoManager.add_task()
    ├─ Validate inputs (non-empty strings)
    ├─ Create Task(id=_next_id, title, description, is_completed=False)
    ├─ Append to _tasks list
    ├─ Increment _next_id
    └─ Return Task object
    ↓
main.py: print(f"Task {task.id} created successfully")
    ↓
User sees: "Task 1 created successfully"
```

## File Structure Details

### src/todo.py (~200 lines)

**Responsibilities**:
- Define `Task` dataclass with type hints
- Implement `TodoManager` class with 6 core methods
- Provide module-level docstrings explaining data model
- Include input validation in manager methods

**Key Methods**:
1. `add_task(title, description)` → Creates task with auto-ID (FR-002, FR-003)
2. `get_all_tasks()` → Returns list copy for display (FR-005)
3. `get_task_by_id(id)` → Finds task or returns None (supports FR-008, FR-009)
4. `update_task(id, title?, description?)` → Modifies existing task (FR-008)
5. `delete_task(id)` → Removes task from list (FR-009)
6. `toggle_completion(id)` → Flips is_completed boolean (FR-006, FR-007)

**Error Handling**:
- Return `None` for missing IDs (caller checks and displays error)
- Validate non-empty strings in `add_task`
- Raise `ValueError` for invalid inputs (caught by handlers)

### src/main.py (~200 lines)

**Responsibilities**:
- Display numbered menu with 6 options (1-5 operations + 6 exit)
- Handle user input parsing and validation
- Call TodoManager methods and format output
- Display error messages for invalid operations (FR-010)

**Handler Functions**:
1. `handle_add_task()` → Prompt for title/description, call manager.add_task()
2. `handle_view_tasks()` → Call manager.get_all_tasks(), format display with status indicators
3. `handle_update_task()` → Prompt for ID + new values, call manager.update_task()
4. `handle_delete_task()` → Prompt for ID, call manager.delete_task()
5. `handle_toggle_completion()` → Prompt for ID, call manager.toggle_completion()

**Display Format** (FR-013):
```
ID | Title              | Status
---+--------------------+----------
1  | Fix login bug      | [X] Completed
2  | Write tests        | [ ] Pending
3  | Update docs        | [ ] Pending
```

**Input Validation** (FR-011):
- Menu choice: Must be 1-6
- Task ID: Must be positive integer
- Title/Description: Must be non-empty strings
- Display clear error for invalid input, re-prompt user

### pyproject.toml (~30 lines)

**UV Configuration**:
```toml
[project]
name = "phase1-todo"
version = "0.1.0"
requires-python = ">=3.13"

[project.scripts]
todo = "src.main:main"

[tool.uv]
dev-dependencies = []
```

**Rationale**:
- Minimal config for UV project initialization
- Entry point script enables `uv run todo` execution
- No external dependencies (empty dev-dependencies)
- Python 3.13+ requirement enforced

### tests/manual_tests.md (~100 lines)

**5 Core Test Scenarios**:
1. **Add Task Test**: Create 3 tasks, verify IDs 1-3 assigned, all show Pending
2. **View Tasks Test**: Display list, verify all fields visible, empty list message when no tasks
3. **Update Task Test**: Modify title only, description only, both fields, verify changes persist
4. **Delete Task Test**: Remove task #2, verify #1 and #3 remain with original IDs
5. **Mark Complete Test**: Toggle task #1 to Completed, toggle again to Pending, verify status changes

**Execution**: Manual walk-through by running `uv run todo` and following test steps

## Logic Flow Diagrams

### Application Startup Flow

```
START
  ↓
Initialize TodoManager (empty _tasks list, _next_id=1)
  ↓
Display Welcome Message
  ↓
Enter Main Menu Loop ─────┐
  ↓                        │
Display Menu Options       │
  ↓                        │
Get User Input             │
  ↓                        │
Match Choice:              │
  1 → Add Task    ─────────┤
  2 → View Tasks  ─────────┤
  3 → Update Task ─────────┤
  4 → Delete Task ─────────┤
  5 → Toggle Status ───────┤
  6 → Exit (BREAK)         │
  _ → Invalid Choice ──────┘
  ↓
Display Exit Message
  ↓
END (all data lost)
```

### Add Task Operation Flow

```
START: handle_add_task(manager)
  ↓
Prompt: "Enter task title: "
  ↓
Read title from input()
  ↓
Is title empty? ──YES→ Display Error, Return to Menu
  ↓ NO
Prompt: "Enter task description: "
  ↓
Read description from input()
  ↓
Is description empty? ──YES→ Display Error, Return to Menu
  ↓ NO
Call: manager.add_task(title, description)
  ↓
manager: Create Task(id=_next_id, title, description, is_completed=False)
  ↓
manager: Append Task to _tasks list
  ↓
manager: Increment _next_id
  ↓
manager: Return Task object
  ↓
Display: "✓ Task {task.id} created: {title}"
  ↓
Return to Main Menu
```

### Update Task Operation Flow

```
START: handle_update_task(manager)
  ↓
Prompt: "Enter task ID to update: "
  ↓
Parse ID as integer (catch ValueError)
  ↓
Call: manager.get_task_by_id(id)
  ↓
Task found? ──NO→ Display "Error: Task not found", Return
  ↓ YES
Display current task details
  ↓
Prompt: "New title (press Enter to skip): "
  ↓
Read new_title (may be empty)
  ↓
Prompt: "New description (press Enter to skip): "
  ↓
Read new_description (may be empty)
  ↓
Both empty? ──YES→ Display "No changes made", Return
  ↓ NO
Call: manager.update_task(id, new_title or None, new_description or None)
  ↓
manager: Find task in _tasks by ID
  ↓
manager: Update non-None fields
  ↓
Display: "✓ Task {id} updated successfully"
  ↓
Return to Main Menu
```

### Toggle Completion Flow

```
START: handle_toggle_completion(manager)
  ↓
Prompt: "Enter task ID to toggle: "
  ↓
Parse ID as integer
  ↓
Call: manager.toggle_completion(id)
  ↓
manager: Find task in _tasks by ID
  ↓
Task found? ──NO→ Return False
  ↓ YES
manager: Flip task.is_completed boolean
  ↓
manager: Return True
  ↓
Success? ──NO→ Display "Error: Task not found"
  ↓ YES
Display: "✓ Task {id} marked as {'Completed' if completed else 'Pending'}"
  ↓
Return to Main Menu
```

## Key Architectural Decisions (ADR Candidates)

### Decision 1: Auto-Incrementing Integer IDs vs UUIDs

**Context**: Tasks need unique identifiers for CRUD operations (FR-003).

**Options Considered**:
1. **Auto-incrementing integers** (1, 2, 3, ...)
2. UUIDs (e.g., `uuid.uuid4()`)
3. Hash-based IDs (e.g., hash of title + timestamp)

**Decision**: **Auto-incrementing integers**

**Rationale**:
- **CLI Simplicity**: Users can type "1" instead of "550e8400-e29b-41d4-a716-446655440000"
- **Spec Compliance**: Spec explicitly requires "unique, auto-incrementing integer ID" (FR-003)
- **User Experience**: Sequential IDs easier to reference in console (e.g., "mark task 5 complete")
- **Implementation**: Simple counter (`_next_id += 1`) vs UUID generation library
- **Phase I Scope**: Single-session usage means no cross-session ID collision risk

**Trade-offs Accepted**:
- IDs create "gaps" after deletion (e.g., 1, 3, 5 after deleting 2, 4)
- No inherent sorting by creation time (though list order preserves this)
- Not suitable for distributed systems (but Phase I is single-user, single-process)

**Consequences**:
- Must never reuse IDs even after deletion (maintain referential integrity)
- Counter must persist for application lifetime (stored in TodoManager instance)
- Simple integer parsing in CLI handlers (`int(input())`)

---

### Decision 2: Console Input Loop vs TUI Library

**Context**: Application needs user interface for menu navigation and data entry (FR-001).

**Options Considered**:
1. **Simple input() loop with print() output** (standard library)
2. Rich TUI library (e.g., `textual`, `urwid`, `prompt_toolkit`)
3. Curses-based interface (stdlib `curses` module)

**Decision**: **Simple input() loop with print() output**

**Rationale**:
- **Zero Dependencies**: Standard library only aligns with Phase I constraint
- **Spec Compliance**: "Simple text-based console menu (Input loops)" explicitly requested
- **Cross-Platform**: `input()`/`print()` work on Windows/Mac/Linux without configuration
- **Simplicity**: No learning curve for TUI framework; focus on business logic
- **Testability**: Simple I/O easier to test than interactive TUI

**Trade-offs Accepted**:
- No real-time updates or interactive navigation (must re-display menu each time)
- Limited formatting (no colors, boxes, or rich text without external deps)
- Manual input validation (TUI libraries often provide built-in validation)

**Consequences**:
- Menu re-displays after every operation (classic CLI pattern)
- Use ASCII art or simple formatting for status indicators ([ ] vs [X])
- Input errors handled with error messages + re-prompt

---

### Decision 3: Flat src/ Structure vs Package Hierarchy

**Context**: Code organization for Python modules (constitution requirement: code in `/src`).

**Options Considered**:
1. **Flat src/ with 2 files** (`todo.py`, `main.py`)
2. Package structure: `src/models/`, `src/services/`, `src/cli/`
3. Single-file application (`src/app.py`)

**Decision**: **Flat src/ with 2 files**

**Rationale**:
- **Phase I Simplicity**: Only ~400-500 lines total; no need for deep hierarchy
- **Clear Separation**: Model+Logic in `todo.py`, Interface in `main.py` achieves modularity
- **Constitution Alignment**: "Smallest viable change" and "simplest viable" principles
- **Easy Navigation**: Only 2 files to understand and maintain
- **Future-Proof**: Can refactor to package structure in Phase II if complexity increases

**Trade-offs Accepted**:
- Less scalable if adding many features (but Phase I scope is fixed)
- No clear import structure for larger teams (but single-developer project)

**Consequences**:
- `from src.todo import TodoManager, Task` in `main.py`
- All business logic in single file (manageable at ~200 lines)
- Tests import directly from `src.todo` and `src.main`

---

### Summary of Architectural Decisions

| Decision | Choice Made | Primary Rationale | ADR Needed? |
|----------|-------------|-------------------|-------------|
| ID Strategy | Auto-increment integers | Spec requirement + CLI simplicity | **YES** - Significant long-term impact |
| UI Pattern | input() loop + print() | Zero dependencies + spec compliance | **YES** - Affects extensibility to Phase II |
| Project Structure | Flat src/ (2 files) | Phase I simplicity + constitution | **YES** - Influences maintainability |
| Status Representation | Boolean (is_completed) | Only 2 states + toggle behavior | NO - Implementation detail |
| Error Handling | Return None/False | Simple, no exceptions for control flow | NO - Standard Python practice |
| Storage Structure | list[Task] | Linear search acceptable for <1K tasks | NO - Performance is adequate |

**ADR Creation**: After plan approval, user can run `/sp.adr` to document the 3 significant decisions.

## Implementation Phases

### Phase 0: Environment Setup (Foundation)

**Objective**: Initialize UV project structure and verify tooling.

**Tasks**:
1. Initialize UV project: `uv init --name phase1-todo`
2. Create `src/` directory structure
3. Configure `pyproject.toml` with Python 3.13+ requirement
4. Verify UV can create virtual environment: `uv venv`
5. Create placeholder files: `src/__init__.py`, `src/todo.py`, `src/main.py`

**Validation**:
- ✅ `uv run python --version` shows Python 3.13+
- ✅ Project structure matches plan diagram
- ✅ No `.git` artifacts present (constitution compliance)

**Artifacts**:
- `pyproject.toml` (configured)
- `src/` directory with 3 files (empty)

---

### Phase 1: Data Model + Business Logic (Core Foundation)

**Objective**: Implement Task dataclass and TodoManager with full CRUD operations.

**Tasks**:
1. Define `Task` dataclass in `src/todo.py` with type hints
2. Implement `TodoManager.__init__()` with empty task list and ID counter
3. Implement `add_task(title, description)` with validation
4. Implement `get_all_tasks()` returning list copy
5. Implement `get_task_by_id(id)` with linear search
6. Implement `update_task(id, title?, description?)` with partial update support
7. Implement `delete_task(id)` with ID preservation
8. Implement `toggle_completion(id)` with boolean flip
9. Add docstrings to all public methods

**Validation**:
- ✅ All methods have type hints
- ✅ PEP 8 compliance (run `ruff check src/todo.py`)
- ✅ Can create task, verify ID increments
- ✅ Can toggle completion, verify boolean flips
- ✅ Delete task, verify ID not reused

**Artifacts**:
- `src/todo.py` (~200 lines, fully typed and documented)

---

### Phase 2: CLI Interface (User Interaction)

**Objective**: Build console menu with handlers for all 5 operations + exit.

**Tasks**:
1. Implement `display_menu()` showing 6 numbered options
2. Implement `main()` loop with `match/case` command routing
3. Implement `handle_add_task()` with input prompts and validation
4. Implement `handle_view_tasks()` with formatted table display
5. Implement `handle_update_task()` with optional field updates
6. Implement `handle_delete_task()` with ID prompt
7. Implement `handle_toggle_completion()` with status display
8. Add input validation for all handlers (empty strings, invalid IDs)
9. Add error messages for invalid operations (FR-010)
10. Implement graceful exit on option 6 (FR-012)

**Validation**:
- ✅ Menu displays correctly with all 6 options
- ✅ Invalid menu choice shows error + re-prompts
- ✅ Empty title/description rejected with error message
- ✅ Non-existent task ID shows "Task not found" error
- ✅ Exit option cleanly terminates application

**Artifacts**:
- `src/main.py` (~200 lines, fully functional CLI)

---

### Phase 3: Integration Testing (Quality Assurance)

**Objective**: Manually validate all 5 core features end-to-end.

**Tasks**:
1. Create `tests/manual_tests.md` with 5 test scenarios
2. Execute Test 1 (Add Task): Create 3 tasks, verify IDs and status
3. Execute Test 2 (View Tasks): Display list, check formatting and empty list message
4. Execute Test 3 (Update Task): Modify title, description, both; verify changes
5. Execute Test 4 (Delete Task): Remove task, verify others remain with original IDs
6. Execute Test 5 (Mark Complete): Toggle status, verify indicators ([X] vs [ ])
7. Execute Edge Case Tests: Empty input, invalid IDs, Unicode characters
8. Document results in `tests/manual_tests.md`

**Validation**:
- ✅ All 5 core features functional
- ✅ All edge cases handled gracefully
- ✅ No crashes or unhandled exceptions
- ✅ Success criteria SC-001 to SC-008 met

**Artifacts**:
- `tests/manual_tests.md` (test scenarios + results)

---

### Phase 4: Documentation + Finalization (Delivery Readiness)

**Objective**: Complete user-facing docs and ensure constitution compliance.

**Tasks**:
1. Write `README.md` with:
   - Project overview and purpose
   - Installation instructions (`uv` setup)
   - Usage guide (how to run `uv run todo`)
   - Feature summary (5 core operations)
   - Limitations (in-memory only, data lost on exit)
2. Verify `CLAUDE.md` reflects current project state
3. Run compliance check:
   - No `.git` artifacts created
   - No persistent storage files
   - All code in `/src` directory
   - Type hints on all functions
   - PEP 8 compliance
4. Final smoke test: Run application, execute all 5 operations, exit cleanly

**Validation**:
- ✅ README.md clear and complete
- ✅ No constitution violations detected
- ✅ Application runs on fresh system with only Python 3.13 + UV
- ✅ All success criteria (SC-001 to SC-008) validated

**Artifacts**:
- `README.md` (user documentation)
- Final compliance report (checklist)

---

### Phase Summary Table

| Phase | Objective | Key Artifacts | Validation Gate |
|-------|-----------|---------------|-----------------|
| 0 | Environment Setup | `pyproject.toml`, `src/` structure | UV project initializes correctly |
| 1 | Data Model + Logic | `src/todo.py` (Task + TodoManager) | All CRUD methods functional, typed |
| 2 | CLI Interface | `src/main.py` (menu + handlers) | All 5 operations work via console |
| 3 | Integration Testing | `tests/manual_tests.md` | All test scenarios pass |
| 4 | Documentation | `README.md`, compliance check | Constitution compliance verified |

**Total Estimated Effort**: 4-6 hours of focused implementation + testing across 4 phases.

**Critical Path**: Phase 1 → Phase 2 (CLI depends on TodoManager). Phases 3-4 can run in parallel after Phase 2 completes.

## Quality Validation Strategy

### Unit-Level Validation (Phase 1)

**Approach**: Temporary validation script to test TodoManager in isolation.

**Script**: `tests/validate_logic.py` (temporary, not committed)

```python
from src.todo import TodoManager

def test_id_incrementing():
    """Verify IDs increment sequentially and never reuse."""
    manager = TodoManager()
    t1 = manager.add_task("Task 1", "Description 1")
    t2 = manager.add_task("Task 2", "Description 2")
    assert t1.id == 1
    assert t2.id == 2
    manager.delete_task(1)
    t3 = manager.add_task("Task 3", "Description 3")
    assert t3.id == 3  # ID 1 not reused
    print("✓ ID incrementing test passed")

def test_status_toggling():
    """Verify toggle_completion flips boolean correctly."""
    manager = TodoManager()
    t1 = manager.add_task("Task 1", "Description 1")
    assert t1.is_completed == False
    manager.toggle_completion(1)
    t1 = manager.get_task_by_id(1)
    assert t1.is_completed == True
    manager.toggle_completion(1)
    t1 = manager.get_task_by_id(1)
    assert t1.is_completed == False
    print("✓ Status toggling test passed")

if __name__ == "__main__":
    test_id_incrementing()
    test_status_toggling()
    print("\n✓ All unit validations passed")
```

**Execution**: `uv run python tests/validate_logic.py`

---

### Integration-Level Validation (Phase 3)

**Approach**: Manual walk-through of all 5 core features via running application.

**Test Scenarios** (from `tests/manual_tests.md`):

#### Test 1: Add Task
1. Run `uv run todo`
2. Select option 1 (Add Task)
3. Enter title: "Fix login bug"
4. Enter description: "Users cannot log in with special characters in password"
5. Verify output: "✓ Task 1 created: Fix login bug"
6. Repeat 2 more times with different titles
7. Verify tasks assigned IDs 2 and 3

**Expected Result**: 3 tasks created with sequential IDs 1, 2, 3

#### Test 2: View Tasks
1. From main menu, select option 2 (View Tasks)
2. Verify table displays all 3 tasks with ID, title, description, status
3. Verify all tasks show "[ ] Pending" status
4. Return to menu, select option 4 (Delete Task) and delete all tasks
5. Select option 2 again
6. Verify message: "No tasks found. Add a task to get started!"

**Expected Result**: Task list displays correctly; empty list shows friendly message

#### Test 3: Update Task
1. Add task: "Write tests" / "Unit tests for todo manager"
2. Select option 3 (Update Task)
3. Enter task ID: 1
4. Enter new title: "Write unit tests"
5. Press Enter to skip description
6. Verify output: "✓ Task 1 updated successfully"
7. View tasks, confirm title changed but description unchanged

**Expected Result**: Partial update works (title only, description only, or both)

#### Test 4: Delete Task
1. Add 5 tasks (IDs 1-5)
2. Delete task ID 2
3. Delete task ID 4
4. View tasks
5. Verify only tasks 1, 3, 5 remain with original IDs (no renumbering)

**Expected Result**: Deleted tasks removed; remaining tasks keep original IDs

#### Test 5: Mark Complete
1. Add task: "Deploy to production" / "Deploy v1.0 to production server"
2. Mark task ID 1 as complete
3. Verify output: "✓ Task 1 marked as Completed"
4. View tasks, verify status shows "[X] Completed"
5. Mark task ID 1 as complete again (toggle)
6. View tasks, verify status shows "[ ] Pending"

**Expected Result**: Toggle behavior works; status indicators update correctly

---

### Compliance Validation (Phase 4)

**Constitution Compliance Checklist**:

```markdown
## Constitution Compliance Validation

### Core Principle 1: Strict Spec-Driven Development
- [ ] All code derived from spec.md (no manual coding outside /sp.tasks)
- [ ] No features implemented beyond spec requirements
- [ ] All FR-001 to FR-015 requirements addressed

### Core Principle 2: Modularity
- [ ] Clear separation: Task (model), TodoManager (logic), main (interface)
- [ ] No cross-layer violations (CLI doesn't directly mutate tasks)

### Core Principle 3: Clean Code Standards
- [ ] PEP 8 compliance verified (run: `ruff check src/`)
- [ ] Type hints on all functions/methods
- [ ] Docstrings on all public classes and functions

### Core Principle 4: Environment Standards
- [ ] UV package manager used (pyproject.toml present)
- [ ] All source code in `/src` directory
- [ ] Python 3.13+ features used (match/case, dataclasses)

### Core Principle 5: ID-Based Management
- [ ] Tasks use auto-incrementing integer IDs starting at 1
- [ ] IDs never reused after deletion
- [ ] All CRUD operations reference tasks by ID

### Core Principle 6: Zero External Dependencies
- [ ] No database files (*.db, *.sqlite)
- [ ] No JSON/CSV files created
- [ ] No network operations
- [ ] Only in-memory storage (list[Task])

### Tool Restriction: No Git/GitHub Operations
- [ ] No `.git` directory created by automation
- [ ] No `git` commands executed during implementation
- [ ] User manually handled version control

### Success Criteria Validation
- [ ] SC-001: Task creation under 5 seconds (manual timing)
- [ ] SC-002: Clear Pending vs Completed distinction (visual check)
- [ ] SC-003: All 5 CRUD operations functional (manual tests)
- [ ] SC-004: 1,000 tasks load in under 1 second (performance test if needed)
- [ ] SC-005: No data persists after exit (verify filesystem)
- [ ] SC-006: Invalid inputs show errors, no crashes (edge case testing)
- [ ] SC-007: ID uniqueness verified (create → delete → create test)
- [ ] SC-008: Runs on Python 3.13+ with UV (fresh install test)
```

**Execution**: Manually review and check each item before final delivery.

---

### Performance Validation (Optional)

**Approach**: Test with large dataset if SC-004 needs explicit validation.

**Script**: `tests/performance_test.py` (temporary)

```python
import time
from src.todo import TodoManager

def test_1000_tasks_performance():
    """Verify operations complete in <1 second with 1,000 tasks."""
    manager = TodoManager()

    # Create 1,000 tasks
    print("Creating 1,000 tasks...")
    start = time.time()
    for i in range(1000):
        manager.add_task(f"Task {i+1}", f"Description {i+1}")
    create_time = time.time() - start
    print(f"  Create time: {create_time:.2f}s")

    # View all tasks
    start = time.time()
    tasks = manager.get_all_tasks()
    view_time = time.time() - start
    print(f"  View time: {view_time:.2f}s ({len(tasks)} tasks)")

    # Update task in middle
    start = time.time()
    manager.update_task(500, "Updated Task 500", None)
    update_time = time.time() - start
    print(f"  Update time: {update_time:.4f}s")

    assert view_time < 1.0, "View operation too slow"
    assert update_time < 1.0, "Update operation too slow"
    print("\n✓ Performance test passed (SC-004)")

if __name__ == "__main__":
    test_1000_tasks_performance()
```

**Execution**: `uv run python tests/performance_test.py` (only if SC-004 validation required)

---

## Risk Analysis and Mitigation

### Risk 1: ID Counter Overflow

**Scenario**: User creates 2^31 tasks in a session, causing integer overflow.

**Likelihood**: Extremely low (Phase I targets 10-1,000 tasks per spec)

**Impact**: Application crash or ID collision

**Mitigation**:
- Python 3 integers have arbitrary precision (no overflow risk in practice)
- Document limitation in README: "Optimized for sessions with <10,000 tasks"
- No action needed for Phase I scope

**Kill Switch**: None (risk negligible for target usage)

---

### Risk 2: Memory Exhaustion

**Scenario**: User creates excessive tasks (e.g., 100,000) and exhausts system RAM.

**Likelihood**: Low (manual task entry limits throughput)

**Impact**: Application slow-down or OS kills process

**Mitigation**:
- Document limitation: "In-memory storage; data lost on crash"
- Future enhancement: Add task count limit warning at 10,000 tasks
- No hard limit for Phase I (spec allows unlimited tasks)

**Kill Switch**: User can restart application (data already volatile)

---

### Risk 3: Invalid Unicode Characters

**Scenario**: User enters emoji or non-ASCII characters causing display issues.

**Likelihood**: Medium (modern users expect emoji support)

**Impact**: Garbled console output or UnicodeEncodeError

**Mitigation**:
- Ensure terminal uses UTF-8 encoding (default on modern systems)
- Test with sample emoji/Unicode during manual testing
- Document in README: "Requires UTF-8-capable terminal"

**Kill Switch**: User avoids problematic characters (or switches terminal)

---

## Open Questions

None at this stage. All architectural decisions made based on spec requirements and constitution constraints. If clarifications arise during implementation, document in PHR and proceed with reasonable defaults.

---

## Next Steps

1. **Review and Approve Plan**: User validates this architectural plan
2. **Optional ADR Creation**: Run `/sp.adr <decision-title>` for 3 significant decisions:
   - `auto-increment-id-strategy`
   - `console-input-loop-ui`
   - `flat-source-structure`
3. **Generate Tasks**: Run `/sp.tasks` to create actionable implementation tasks from this plan
4. **Implementation**: Execute tasks in 4 phases (Foundation → Logic → Interface → Finalization)
5. **Manual Validation**: Run all 5 test scenarios from `tests/manual_tests.md`
6. **Delivery**: Constitution compliance check + README completion

**Estimated Timeline**: Plan → Tasks (1 hour) → Implementation (4-6 hours) → Testing (1 hour) → Documentation (1 hour) = ~7-9 hours total for Phase I MVP.

---

**Plan Status**: Draft → Ready for Review
**Blockers**: None
**Dependencies**: Spec.md (completed), Constitution.md (ratified)
